# Large data files
data/raw/*.json
data/processed/*.parquet

# Allow the 200K dataset (62MB - under GitHub limit)
!data/deep_learning_data/movies_reviews_200k.parquet

# Model files (large binary files)
*.keras
*.model
*.npy
results/**/*.pkl
results/**/*.keras
results/**/*.model
results/**/*.npy

# Keep PNG visualizations and analysis notebooks
!results/**/*.png
!*.ipynb

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/

# Jupyter
.ipynb_checkpoints
